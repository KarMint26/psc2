{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioIP9j3NKN87"
      },
      "source": [
        "# 1 Pengolahan Hasil Face Landmark (untuk Analisis / Training)\n",
        "\n",
        "ðŸŽ¯ Tujuan:\n",
        "1. Mendapatkan data (x, y, z) dari landmark wajah\n",
        "\n",
        "2. Bisa dipakai untuk klasifikasi, analisis ekspresi, atau training ML\n",
        "\n",
        "\n",
        "ðŸŽ¯ Setelah dapat landmark dari Face Mesh atau Face Landmarker, kita bisa:\n",
        "* Ambil koordinat (x, y, z) dari tiap titik wajah\n",
        "\n",
        "* Simpan dalam array atau dataframe\n",
        "\n",
        "* Normalize data (misalnya terhadap bounding box wajah)\n",
        "\n",
        "* Simpan ke file .csv buat training model ML\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-14T07:39:43.497253Z",
          "start_time": "2025-04-14T07:39:43.486025Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "zWcWr0fAURrN",
        "outputId": "960a53a4-a251-4f34-a808-90bdde228385"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import mediapipe as mp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-14T07:38:50.473834Z",
          "start_time": "2025-04-14T07:38:50.413856Z"
        },
        "id": "ItLjXop9KIYO"
      },
      "outputs": [],
      "source": [
        "landmark_list = []\n",
        "for lm in face_landmarks.landmark:\n",
        "    landmark_list.extend([lm.x, lm.y, lm.z])\n",
        "\n",
        "# lm.x, lm.y, lm.z adalah koordinat relatif (dalam skala 0â€“1)\n",
        "# Jumlah total titik: 468 landmark (default Face Mesh)\n",
        "# Bisa dikurangi ke area tertentu (misal: mata, bibir, dll)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nd2VJkGeLtdI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "coords = np.array([[lm.x, lm.y, lm.z] for lm in face_landmarks.landmark])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PK_tfC5qL0P7"
      },
      "outputs": [],
      "source": [
        "# Misal normalisasi terhadap titik tengah wajah (titik ke-1)\n",
        "ref_x = face_landmarks.landmark[1].x\n",
        "ref_y = face_landmarks.landmark[1].y\n",
        "\n",
        "normalized = []\n",
        "for lm in face_landmarks.landmark:\n",
        "    normalized.append([lm.x - ref_x, lm.y - ref_y])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qq58mhjAKyGR"
      },
      "source": [
        "# 2 Ekstraksi ke CSV dari Webcam atau Video\n",
        "\n",
        "ðŸŽ¯ Tujuan:\n",
        "* Menyimpan hasil koordinat landmark (dan label, kalau ada)\n",
        "\n",
        "* Bisa digunakan untuk machine learning, data analisis, atau pembuatan dataset gesture/ekspresi\n",
        "\n",
        "ðŸŽ¯ Kita bisa bikin skrip untuk:\n",
        "\n",
        "* Baca webcam / video\n",
        "\n",
        "* Proses wajah per frame\n",
        "\n",
        "* Simpan data landmark + label (jika ada)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKzyMItZMOat"
      },
      "outputs": [],
      "source": [
        "# Setiap baris = 1 frame\n",
        "# Setiap kolom = koordinat landmark (x1, y1, z1, x2, y2, z2, ..., label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-14T07:41:12.539588Z",
          "start_time": "2025-04-14T07:40:57.389570Z"
        },
        "id": "tkRBSr9SK-qO"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import csv\n",
        "\n",
        "# Inisialisasi MediaPipe\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=False, refine_landmarks=True)\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "\n",
        "# Buka webcam / video\n",
        "cap = cv2.VideoCapture(0)  # ganti dengan path video kalau pakai dataset\n",
        "\n",
        "# Siapkan file CSV\n",
        "csv_file = open('landmark_output_netral.csv', mode='w', newline='')\n",
        "csv_writer = csv.writer(csv_file)\n",
        "\n",
        "# Tulis header CSV (x1, y1, z1, ..., label)\n",
        "header = []\n",
        "for i in range(468):  # atau ganti jumlah titik jika dibatasi\n",
        "    header += [f'x{i}', f'y{i}', f'z{i}']\n",
        "header.append('label')  # kalau pakai label gesture / ekspresi\n",
        "csv_writer.writerow(header)\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Proses frame\n",
        "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    results = face_mesh.process(rgb)\n",
        "\n",
        "    if results.multi_face_landmarks:\n",
        "        for face_landmarks in results.multi_face_landmarks:\n",
        "            row = []\n",
        "            for lm in face_landmarks.landmark:\n",
        "                row += [lm.x, lm.y, lm.z]\n",
        "\n",
        "            label = 'neutral'  # bisa disesuaikan manual atau dari sistem\n",
        "            row.append(label)\n",
        "            csv_writer.writerow(row)\n",
        "\n",
        "    # Tampilkan (opsional)\n",
        "    cv2.imshow('Recording Face Landmark', frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Tutup semua\n",
        "csv_file.close()\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmGXmL6EMjVZ"
      },
      "source": [
        "# 3 Implementasi MediaPipe ke Dataset Offline (Video/Image)\n",
        "\n",
        "ðŸŽ¯ Tujuan:\n",
        "* Menggunakan MediaPipe bukan dari webcam langsung, tapi dari file video atau folder gambar sebagai dataset.\n",
        "\n",
        "ðŸŽ¯ Ada 2 jenis dataset offline:\n",
        "1. Dataset Berupa File Video (.mp4, .avi, dsb)\n",
        "2. Dataset Berupa Gambar (folder berisi .jpg, .png, dll)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-14T07:50:02.845719Z",
          "start_time": "2025-04-14T07:49:54.500262Z"
        },
        "id": "SzcCe6qGM_dK"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1744855057.073342    7995 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
            "I0000 00:00:1744855057.080896    8046 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 22.2.5), renderer: STONEY (stoney, LLVM 15.0.6, DRM 3.42, 5.15.0-76-generic)\n",
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
            "W0000 00:00:1744855057.142163    8039 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "W0000 00:00:1744855057.196077    8040 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "W0000 00:00:1744855058.375120    8039 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
          ]
        }
      ],
      "source": [
        "# Proses Dataset Berupa Video\n",
        "\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import csv\n",
        "\n",
        "# Inisialisasi MediaPipe\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=False, refine_landmarks=True)\n",
        "\n",
        "# Buka file video\n",
        "video_path = \"dataset/video/Abuse006_x264_21.mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Siapkan file CSV\n",
        "csv_file = open('video_landmark_output_video.csv', mode='w', newline='')\n",
        "csv_writer = csv.writer(csv_file)\n",
        "\n",
        "# Tulis header\n",
        "header = []\n",
        "for i in range(468):\n",
        "    header += [f'x{i}', f'y{i}', f'z{i}']\n",
        "header.append('label')\n",
        "csv_writer.writerow(header)\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    results = face_mesh.process(rgb)\n",
        "\n",
        "    if results.multi_face_landmarks:\n",
        "        for face_landmarks in results.multi_face_landmarks:\n",
        "            row = []\n",
        "            for lm in face_landmarks.landmark:\n",
        "                row += [lm.x, lm.y, lm.z]\n",
        "            row.append('senyum')  # contoh label manual dari nama video\n",
        "            csv_writer.writerow(row)\n",
        "\n",
        "cap.release()\n",
        "csv_file.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-14T08:17:55.863321Z",
          "start_time": "2025-04-14T08:17:55.729477Z"
        },
        "id": "lotMnmCWNF0o"
      },
      "outputs": [],
      "source": [
        "# Proses Dataset Berupa Gambar dalam Folder\n",
        "\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import os\n",
        "import csv\n",
        "\n",
        "# Inisialisasi Face Mesh\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, refine_landmarks=True)\n",
        "\n",
        "# Folder gambar\n",
        "image_folder = \"dataset/gambar/\"\n",
        "image_list = os.listdir(image_folder)\n",
        "\n",
        "# Siapkan CSV\n",
        "csv_file = open('gambar_landmark_output_gambar.csv', mode='w', newline='')\n",
        "csv_writer = csv.writer(csv_file)\n",
        "\n",
        "# Tulis header\n",
        "header = []\n",
        "for i in range(468):\n",
        "    header += [f'x{i}', f'y{i}', f'z{i}']\n",
        "header.append('label')\n",
        "csv_writer.writerow(header)\n",
        "\n",
        "for img_name in image_list:\n",
        "    path = os.path.join(image_folder, img_name)\n",
        "    img = cv2.imread(path)\n",
        "    rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    results = face_mesh.process(rgb)\n",
        "\n",
        "    if results.multi_face_landmarks:\n",
        "        for face_landmarks in results.multi_face_landmarks:\n",
        "            row = []\n",
        "            for lm in face_landmarks.landmark:\n",
        "                row += [lm.x, lm.y, lm.z]\n",
        "            # contoh: ambil label dari nama file, misalnya senyum_1.jpg\n",
        "            label = img_name.split('_')[0]\n",
        "            row.append(label)\n",
        "            csv_writer.writerow(row)\n",
        "\n",
        "csv_file.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUfMFxYyNjI8"
      },
      "source": [
        "# 4 Gesture Detection / Face Analysis\n",
        "ðŸŽ¯ Tujuan:\n",
        "* Menganalisis ekspresi atau gesture wajah (misalnya senyum, kedipan, buka mulut) berdasarkan koordinat landmark dari MediaPipe.\n",
        "\n",
        "**Konsep Umum: Analisis Berdasarkan Jarak / Rasio**\n",
        "\n",
        "ðŸŽ¯ Contoh-contoh gesture atau ekspresi:\n",
        "* Senyum â†’ bibir melebar\n",
        "\n",
        "* Mata tertutup â†’ tinggi mata menurun\n",
        "\n",
        "* Mulut terbuka â†’ jarak atas-bawah bibir besar\n",
        "\n",
        "* Mengangguk / menggeleng â†’ arah kepala berubah"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-14T08:40:41.055224Z",
          "start_time": "2025-04-14T08:40:41.037751Z"
        },
        "id": "IbdiO1rHN9os"
      },
      "outputs": [],
      "source": [
        "# Deteksi Mulut Terbuka\n",
        "import math\n",
        "\n",
        "def euclidean_distance(p1, p2):\n",
        "    return math.sqrt((p1.x - p2.x)**2 + (p1.y - p2.y)**2)\n",
        "\n",
        "# Misalnya deteksi dari FaceMesh\n",
        "top_lip = face_landmarks.landmark[13]\n",
        "bottom_lip = face_landmarks.landmark[14]\n",
        "\n",
        "# Hitung jarak antara bibir atas & bawah\n",
        "mouth_distance = euclidean_distance(top_lip, bottom_lip)\n",
        "\n",
        "if mouth_distance > 0.05:\n",
        "    print(\"Mulut terbuka\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQJ54C7bOC0A"
      },
      "outputs": [],
      "source": [
        "# Deteksi Kedipan Mata (Eye Aspect Ratio)\n",
        "# Titik sekitar mata kiri (misalnya)\n",
        "left_eye_top = face_landmarks.landmark[386]\n",
        "left_eye_bottom = face_landmarks.landmark[374]\n",
        "\n",
        "eye_distance = euclidean_distance(left_eye_top, left_eye_bottom)\n",
        "\n",
        "if eye_distance < 0.01:\n",
        "    print(\"Mata kiri terpejam\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipKKAj6YOI8_"
      },
      "outputs": [],
      "source": [
        "# Deteksi Senyum\n",
        "left_lip = face_landmarks.landmark[61]\n",
        "right_lip = face_landmarks.landmark[291]\n",
        "\n",
        "lip_width = euclidean_distance(left_lip, right_lip)\n",
        "\n",
        "if lip_width > 0.3:\n",
        "    print(\"Senyum\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-14T08:44:16.289293Z",
          "start_time": "2025-04-14T08:43:16.328614Z"
        },
        "id": "Ei-ex1MQURrb"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import math\n",
        "\n",
        "# Fungsi untuk hitung jarak\n",
        "def distance(p1, p2):\n",
        "    return ((p1.x - p2.x)**2 + (p1.y - p2.y)**2) ** 0.5\n",
        "\n",
        "# Inisialisasi Face Mesh\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True)\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "\n",
        "# Buka Webcam\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Preprocess\n",
        "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    results = face_mesh.process(rgb)\n",
        "\n",
        "    label = \"\"\n",
        "\n",
        "    if results.multi_face_landmarks:\n",
        "        for landmarks in results.multi_face_landmarks:\n",
        "            # Ambil titik-titik bibir untuk analisis\n",
        "            left_lip = landmarks.landmark[61]\n",
        "            right_lip = landmarks.landmark[291]\n",
        "            top_lip = landmarks.landmark[13]\n",
        "            bottom_lip = landmarks.landmark[14]\n",
        "\n",
        "            # Jarak horizontal dan vertikal bibir\n",
        "            lip_width = distance(left_lip, right_lip)\n",
        "            mouth_open = distance(top_lip, bottom_lip)\n",
        "\n",
        "            # Threshold sederhana (bisa di-tune)\n",
        "            label_list = []\n",
        "            if mouth_open > 0.05:\n",
        "                label_list.append(\"Mulut Terbuka\")\n",
        "            if lip_width > 0.15:\n",
        "                label_list.append(\"Senyum\")\n",
        "\n",
        "            label = \" & \".join(label_list) if label_list else \"Netral\"\n",
        "\n",
        "            # Gambar landmark wajah\n",
        "            mp_drawing.draw_landmarks(\n",
        "                frame,\n",
        "                landmarks,\n",
        "                mp_face_mesh.FACEMESH_TESSELATION,\n",
        "                landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0,255,0), thickness=1, circle_radius=1),\n",
        "                connection_drawing_spec=mp_drawing.DrawingSpec(color=(0,128,255), thickness=1)\n",
        "            )\n",
        "\n",
        "    # Tampilkan label prediksi\n",
        "    cv2.putText(frame, f'Prediksi: {label}', (30, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "\n",
        "    # Tampilkan frame\n",
        "    cv2.imshow(\"Deteksi Ekspresi Real-time\", frame)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1744857172.259086    7995 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
            "I0000 00:00:1744857172.272582    9054 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 22.2.5), renderer: STONEY (stoney, LLVM 15.0.6, DRM 3.42, 5.15.0-76-generic)\n",
            "W0000 00:00:1744857172.283156    9052 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "W0000 00:00:1744857172.347347    9051 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 84\u001b[0m\n\u001b[1;32m     81\u001b[0m cv2\u001b[38;5;241m.\u001b[39mputText(frame, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrediksi: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, (\u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m40\u001b[39m), cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[38;5;241m1\u001b[39m, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Tampilkan frame\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDeteksi Ekspresi Real-time\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Mulut Membuka Tertutup & Mata Terbuka Tertutup\n",
        "\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import math\n",
        "\n",
        "# Fungsi untuk hitung jarak Euclidean\n",
        "def distance(p1, p2):\n",
        "    return ((p1.x - p2.x)**2 + (p1.y - p2.y)**2) ** 0.5\n",
        "\n",
        "# Fungsi untuk menghitung Eye Aspect Ratio (EAR)\n",
        "def calculate_ear(eye_landmarks, landmarks):\n",
        "    p1 = landmarks[eye_landmarks[0]]  # Titik horizontal kiri\n",
        "    p2 = landmarks[eye_landmarks[1]]  # Titik vertikal atas 1\n",
        "    p3 = landmarks[eye_landmarks[2]]  # Titik vertikal atas 2\n",
        "    p4 = landmarks[eye_landmarks[3]]  # Titik horizontal kanan\n",
        "    p5 = landmarks[eye_landmarks[4]]  # Titik vertikal bawah 1\n",
        "    p6 = landmarks[eye_landmarks[5]]  # Titik vertikal bawah 2\n",
        "\n",
        "    vertical_1 = distance(p2, p6)\n",
        "    vertical_2 = distance(p3, p5)\n",
        "    horizontal = distance(p1, p4)\n",
        "\n",
        "    ear = (vertical_1 + vertical_2) / (2.0 * horizontal)\n",
        "    return ear\n",
        "\n",
        "# Inisialisasi Face Mesh\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True)\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "\n",
        "# Indeks landmark untuk mata kiri dan kanan\n",
        "LEFT_EYE = [362, 385, 387, 263, 373, 380]\n",
        "RIGHT_EYE = [33, 160, 158, 133, 153, 144]\n",
        "\n",
        "# Buka Webcam\n",
        "cap = cv2.VideoCapture(1)\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Preprocess\n",
        "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    results = face_mesh.process(rgb)\n",
        "\n",
        "    label = \"\"\n",
        "\n",
        "    if results.multi_face_landmarks:\n",
        "        for landmarks in results.multi_face_landmarks:\n",
        "            # Hitung EAR untuk mata kiri dan kanan\n",
        "            left_ear = calculate_ear(LEFT_EYE, landmarks.landmark)\n",
        "            right_ear = calculate_ear(RIGHT_EYE, landmarks.landmark)\n",
        "            avg_ear = (left_ear + right_ear) / 2.0\n",
        "\n",
        "            # Deteksi mata terbuka atau tertutup\n",
        "            eye_status = \"Mata Terbuka\" if avg_ear >= 0.2 else \"Mata Tertutup\"\n",
        "\n",
        "            # Ambil titik-titik bibir untuk analisis mulut\n",
        "            top_lip = landmarks.landmark[13]\n",
        "            bottom_lip = landmarks.landmark[14]\n",
        "\n",
        "            # Jarak vertikal bibir\n",
        "            mouth_open = distance(top_lip, bottom_lip)\n",
        "\n",
        "            # Deteksi mulut terbuka atau tertutup\n",
        "            mouth_status = \"Mulut Terbuka\" if mouth_open > 0.05 else \"Mulut Tertutup\"\n",
        "\n",
        "            # Gabungkan label\n",
        "            label = f\"{eye_status} & {mouth_status}\"\n",
        "\n",
        "            # Gambar landmark wajah\n",
        "            mp_drawing.draw_landmarks(\n",
        "                frame,\n",
        "                landmarks,\n",
        "                mp_face_mesh.FACEMESH_TESSELATION,\n",
        "                landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=1, circle_radius=1),\n",
        "                connection_drawing_spec=mp_drawing.DrawingSpec(color=(0, 128, 255), thickness=1)\n",
        "            )\n",
        "\n",
        "    # Tampilkan label prediksi\n",
        "    cv2.putText(frame, f'Prediksi: {label}', (30, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "\n",
        "    # Tampilkan frame\n",
        "    cv2.imshow(\"Deteksi Ekspresi Real-time\", frame)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myvenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
